# 使用 NebulaGraph Operator 安装{{nebula.name}}集群

采用 NebulaGraph Operator 安装{{nebula.name}}集群，能够实现集群管理的自动化，同时具备自动错误恢复的功能。本文介绍`kubectl apply`和`helm`两种方式来使用 NebulaGraph Operator 安装{{nebula.name}}集群。

!!! compatibility "历史版本兼容性"

    1.x 版本的 NebulaGraph Operator 不兼容 3.x 以下版本的{{nebula.name}}。

## 前提条件

- [安装 NebulaGraph Operator](../../2.get-started/2.1.install-operator.md)
- [已创建 StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/)

## 使用`kubectl apply`

1. 创建命名空间，用于存放{{nebula.name}}集群相关资源。例如，创建`nebula`命名空间。

  ```bash
  kubectl create namespace nebula
  ```

2. 创建集群的 YAML 配置文件`nebulacluster.yaml`。例如，创建名为`nebula`的集群。

  ??? info "展开查看`nebula`集群的示例配置"

      ```yaml
      apiVersion: apps.nebula-graph.io/v1alpha1
      kind: NebulaCluster
      metadata:
        name: nebula
        namespace: default
      spec:
        # 控制 Pod 的调度策略。
        topologySpreadConstraints:
        - topologyKey: "kubernetes.io/hostname"
          whenUnsatisfiable: "ScheduleAnyway"
        # 是否回收 PV。
        enablePVReclaim: false
        # 是否启用备份和恢复功能。
        exporter:
          image: vesoft/nebula-stats-exporter
          version: v3.3.0
          replicas: 1
          maxRequests: 20
        # 自定义 Agent 镜像，用于集群备份和恢复及日志清理。
        agent:
          image: vesoft/nebula-agent
          version: latest
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "200m"
              memory: "256Mi"  
        # 配置镜像拉取策略。
        imagePullPolicy: Always
        # 选择 Pod 被调度的节点。
        nodeSelector:
          nebula: cloud
        # 依赖的控制器名称。
        reference:
          name: statefulsets.apps
          version: v1
        # 调度器名称。
        schedulerName: default-scheduler   
        # 启动 NebulaGraph Console 服务，用于连接 Graph 服务。
        console:
          image: vesoft/nebula-console
          version: nightly
          username: "demo"
          password: "test"                 
        # Graph 服务的相关配置。 
        graphd:
        # 用于检测 Graph 服务是否正常运行。
        #  readinessProbe:
        #    failureThreshold: 3
        #    httpGet:
        #      path: /status
        #      port: 19669
        #      scheme: HTTP
        #    initialDelaySeconds: 40
        #    periodSeconds: 10
        #    successThreshold: 1
        #    timeoutSeconds: 10
          # Graph 服务的容器镜像。
          image: vesoft/nebula-graphd
          logVolumeClaim:
            resources:
              requests:
                storage: 2Gi
            # 用于存储 Graph 服务的日志的存储类名称。
            storageClassName: local-sc
          # Graph 服务的 Pod 副本数。
          replicas: 1
          # Graph 服务的资源配置。
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 500Mi
          # Graph 服务的版本。
          version: v{{nebula.release}}
          # 自定义 Graph 服务的 flags 配置项。
          config: {}
        # Meta 服务的相关配置。
        metad:
        #  readinessProbe:
        #    failureThreshold: 3
        #    httpGet:
        #      path: /status
        #      port: 19559
        #      scheme: HTTP
        #    initialDelaySeconds: 5
        #    periodSeconds: 5
        #    successThreshold: 1
        #   timeoutSeconds: 5
          # Meta 服务的容器镜像。
          image: vesoft/nebula-metad
          logVolumeClaim:
            resources:
              requests:
                storage: 2Gi
            storageClassName: local-sc
          dataVolumeClaim:
            resources:
              requests:
                storage: 2Gi
            storageClassName: local-sc
          replicas: 1
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 500Mi
          version: v{{nebula.release}}
          # 自定义 Meta 服务的 flags 配置项。
          config: {}          
        # Storage 服务的相关配置。
        storaged:
        #  readinessProbe:
        #    failureThreshold: 3
        #    httpGet:
        #      path: /status
        #      port: 19779
        #      scheme: HTTP
        #    initialDelaySeconds: 40
        #    periodSeconds: 10
        #    successThreshold: 1
        #    timeoutSeconds: 5
          # Storage 服务的容器镜像。
          image: vesoft/nebula-storaged
          logVolumeClaim:
            resources:
              requests:
                storage: 2Gi
            storageClassName: local-sc
          dataVolumeClaims:
          - resources:
              requests:
                storage: 2Gi
            storageClassName: local-sc
          replicas: 1
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 500Mi
          version: v{{nebula.release}}
          # 自定义 Storage 服务的 flags 配置项。
          config: {} 
      ```  

  有关参数的详细说明，请参见下文的**集群配置参数**。


3. 创建{{nebula.name}}集群。

  ```bash
  kubectl create -f apps_v1alpha1_nebulacluster.yaml -n nebula
  ```

  返回：

  ```bash
  nebulacluster.apps.nebula-graph.io/nebula created
  ```

  如果不通过`-n`指定命名空间，默认使用`default`命名空间。


4. 查看{{nebula.name}}集群状态。
   
  ```bash
  kubectl get nebulaclusters nebula -n nebula
  ```

  返回：

  ```bash
  NAME      READY   GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE
  nebula    True    1                1              1               1             1                  1                86s
  ```

## 使用`helm`

1. 添加 NebulaGraph Operator Helm 仓库（如果已添加，执行下步骤）。
   
  ```bash
  helm repo add nebula-operator https://vesoft-inc.github.io/nebula-operator/charts
  ```

2. 更新 Helm 仓库，拉取最新仓库资源。
   
  ```bash
  helm repo update nebula-operator
  ```

3. 为安装集群所需的配置参数设置环境变量。
   
  ```bash
  export NEBULA_CLUSTER_NAME=nebula         #{{nebula.name}}集群的名字。
  export NEBULA_CLUSTER_NAMESPACE=nebula    #{{nebula.name}}集群所处的命名空间的名字。
  export STORAGE_CLASS_NAME=local-sc         #{{nebula.name}}集群的 StorageClass。
  ```

4. 为{{nebula.name}}集群创建命名空间（如已创建，略过此步）。

  ```bash
  kubectl create namespace "${NEBULA_CLUSTER_NAMESPACE}"
  ```


5. 查看创建集群时，`nebula-operator`的`nebula-cluster` chart 的可自定义的配置项。
  
  - 执行以下命令查看所有可以配置的参数。

    ```bash
    helm show values nebula-operator/nebula-cluster
    ```

  - 单击 [nebula-cluster/values.yaml
](https://github.com/vesoft-inc/nebula-operator/blob/{{operator.branch}}/charts/nebula-cluster/values.yaml) 查看{{nebula.name}}集群的所有配置参数。单击 [Chart parameters](https://github.com/vesoft-inc/nebula-operator/blob/{{operator.branch}}/doc/user/nebula_cluster_helm_guide.md#optional-chart-parameters) 查看参数的描述及默认值。

6. 创建{{nebula.name}}集群。

  通过`--set`参数自定义{{nebula.name}}集群配置项的默认值，例如，`--set nebula.storaged.replicas=3`可设置{{nebula.name}}集群中 Storage 服务的副本数为 3。

  ```bash
  helm install "${NEBULA_CLUSTER_NAME}" nebula-operator/nebula-cluster \
      
      # 指定集群 chart 的版本，不指定则默认安装最新版本 chart。
      # 执行 helm search repo -l nebula-operator/nebula-cluster 命令可查看所有 chart 版本。
      --version={{operator.release}} \
      # 指定{{nebula.name}}集群所处的命名空间。
      --namespace="${NEBULA_CLUSTER_NAMESPACE}" \
      # 自定义 chart 发布名称。
      --set nameOverride="${NEBULA_CLUSTER_NAME}" \
      --set nebula.storageClassName="${STORAGE_CLASS_NAME}" \
      # 指定{{nebula.name}}集群的版本。
      --set nebula.version=v{{nebula.release}} 
  ``` 

7. 查看{{nebula.name}}集群 Pod 的启动状态。
   
  ```bash
  kubectl -n "${NEBULA_CLUSTER_NAMESPACE}" get pod -l "app.kubernetes.io/cluster=${NEBULA_CLUSTER_NAME}"
  ```

  返回： 

  ```bash
  NAME                               READY   STATUS    RESTARTS   AGE
  nebula-exporter-854c76989c-mp725   1/1     Running   0          14h
  nebula-graphd-0                    1/1     Running   0          14h
  nebula-graphd-1                    1/1     Running   0          14h
  nebula-metad-0                     1/1     Running   0          14h
  nebula-metad-1                     1/1     Running   0          14h
  nebula-metad-2                     1/1     Running   0          14h
  nebula-storaged-0                  1/1     Running   0          14h
  nebula-storaged-1                  1/1     Running   0          14h
  nebula-storaged-2                  1/1     Running   0          14h
  ```

## 集群配置参数

以下表格列出了使用 YAML 文件创建{{nebula.name}}集群时，可配置的参数及描述。

  | 参数                                                        | 默认值                   | 描述                                                                                                                                                                                                           |
  | :---------------------------------------------------------- | :----------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
  | `metadata.name`                                             | -                        | 创建的{{nebula.name}}集群名称。                                                                                                                                                                                |
  | `spec.console`                                              | -                        | 启动 Console 容器用于连接 Graph 服务。配置详情，参见 [nebula-console](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/doc/user/nebula_console.md#nebula-console).                     |
  | `spec.topologySpreadConstraints` | -                        | 控制 Pod 的调度策略。详情参见 [Topology Spread Constraints](https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/)。当`topologyKey`的值为`kubernetes.io/zone`时，`whenUnsatisfiable`的值需为`DoNotSchedule`并且`spec.schedulerName`的值为`nebula-scheduler`。                                                               |
  | `spec.graphd.replicas`                                      | `1`                      | Graphd 服务的副本数。                                                                                                                                                                                          |
  | `spec.graphd.image`                                         | `vesoft/nebula-graphd`   | Graphd 服务的容器镜像。                                                                                                                                                                                        |
  | `spec.graphd.version`                                       | `{{nebula.tag}}`         | Graphd 服务的版本号。                                                                                                                                                                                          |
  | `spec.graphd.service`                                       |                          | 访问 Graphd 服务的 Service 配置。                                                                                                                                                                              |
  | `spec.graphd.logVolumeClaim.storageClassName`               | -                        | Graphd 服务的日志盘存储卷的存储类名称。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。             |
  | `spec.metad.replicas`                                       | `1`                      | Metad 服务的副本数。                                                                                                                                                                                           |
  | `spec.metad.image`                                          | `vesoft/nebula-metad`    | Metad 服务的容器镜像。                                                                                                                                                                                         |
  | `spec.metad.version`                                        | `{{nebula.tag}}`         | Metad 服务的版本号。                                                                                                                                                                                           |
  | `spec.metad.dataVolumeClaim.storageClassName`               | -                        | Metad 服务的数据盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。                        |
  | `spec.metad.logVolumeClaim.storageClassName`                | -                        | Metad 服务的日志盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。                        |
  | `spec.storaged.replicas`                                    | `3`                      | Storaged 服务的副本数。                                                                                                                                                                                        |
  | `spec.storaged.image`                                       | `vesoft/nebula-storaged` | Storaged 服务的容器镜像。                                                                                                                                                                                      |
  | `spec.storaged.version`                                     | `{{nebula.tag}}`         | Storaged 服务的版本号。                                                                                                                                                                                        |
  | `spec.storaged.dataVolumeClaims.resources.requests.storage` | -                        | Storaged 服务的数据盘存储大小，可指定多块数据盘存储数据。当指定多块数据盘时，路径为：`/usr/local/nebula/data1`、`/usr/local/nebula/data2`等。                                                                  |
  | `spec.storaged.dataVolumeClaims.storageClassName` | -                        | Storaged 服务的数据盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。                     |
  | `spec.storaged.logVolumeClaim.storageClassName`             | -                        | Storaged 服务的日志盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。                     |
  | `spec.<metad|storaged|graphd>.securityContext`              | `{}`                     | 定义集群容器的权限和访问控制，以控制访问和执行容器的操作。详情参见 [SecurityContext](https://github.com/vesoft-inc/nebula-operator/blob/{{operator.branch}}/doc/user/security_context.md)。                    |
  | `spec.agent`                                                | `{}`                     | Agent 服务的配置。用于备份和恢复及日志清理功能，如果不自定义该配置，将使用默认配置。                                                                                                                           |
  | `spec.reference.name`                                       | `{}`                        | 依赖的控制器名称。                                                                                                                                                                                             |
  | `spec.schedulerName`                                        | `default-scheduler`      | 调度器名称。                                                                                                                                                                                                   |
  | `spec.imagePullPolicy`                                      |       ` Always`                  | {{nebula.name}}镜像的拉取策略。关于拉取策略详情，请参考 [Image pull policy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy)。                                                        |
  | `spec.logRotate`                                            | `{}`                     | 日志轮转配置。详情参见[管理集群日志](../4.5.logging.md)。                                                                                                                                                      |
  | `spec.enablePVReclaim`                                      | `false`                  | 定义是否在删除集群后自动删除 PVC 以释放数据。详情参见[回收 PV](../4.4.storage-management/4.4.3.configure-pv-reclaim.md)。                                                                                      |
