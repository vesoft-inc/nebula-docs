# {{nebula.name}}集群中使用本地持久化存储卷

本地持久化存储卷（Local Persistent Volumes，Local PV）在 K8s 中，直接使用节点的本地磁盘目录存储容器数据。相比网络存储，Local PV 提供更高的 IOPS 和更低的读写延迟，适合数据密集型应用。本文介绍如何在{{nebula.name}}集群中使用 Local PV 以及在使用 Local PV 过程中节点发生故障的处理方法。

虽然使用 Local PV 能提升性能，但是不同于网络存储，本地存储数据不会自动备份。如果节点因任何原因停止，本地存储上的所有数据可能会丢失。因此，使用 Local PV 时，需要在服务可用性、数据持久性和灵活性方面做出一定权衡取舍。

## 背景信息

K8s中，数据的持久化主要依赖于[持久存储卷（Persistent Volume，PV）](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)。K8s 提供的 PV 类型主要分为大致可以分为本地存储和网络存储两类。详情参见[持久化存储卷类型](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes)。

## 前提条件

已安装 NebulaGraph Operator。详情参见[安装 NebulaGraph Operator](../../2.get-started/2.1.install-operator.md)。

## 使用 Local PV

使用 Local PV 涉及到配置本地存储、创建 Local PV 等步骤。静态配置 PV 工具 [Local Persistence Volume Static Provisioner](https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner#overview) 可以自动化管理 Local PV。 Local PV 需要在每个节点上手动配置存储卷，放在特定目录下后，Local Persistence Volume Static Provisioner 就会自动为它们创建相应的 PV，并在不需要时清理这些 PV。

1. 准备和配置本地存储盘。
   
  针对不同磁盘挂载方式，需要在每个节点上做不同的准备和配置工作。详情参见 [Prepare and set up local volumes in discovery directory](https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner/blob/master/docs/operations.md#prepare-and-set-up-local-volumes-in-discovery-directory)。
  
 
2. 创建示例文件名为`default_example_storageclass.yaml`的 StorageClass。

  ```bash
  kubectl create -f deployment/kubernetes/example/default_example_storageclass.yaml
  ```

  该 StorageClass 的配置文件内容如下所示：

  ```yaml
  # Only create this for K8s 1.9+
  apiVersion: storage.k8s.io/v1
  kind: StorageClass
  metadata:
    name: local-storage
  provisioner: kubernetes.io/no-provisioner
  volumeBindingMode: WaitForFirstConsumer
  # Supported policies: Delete, Retain
  reclaimPolicy: Delete
  ```
  
  !!! note

        Local PV 的`volumeBindingMode`必须设置为`WaitForFirstConsumer`。详情参见 [How to Use a Local Persistent Volume](https://kubernetes.io/blog/2019/04/04/kubernetes-1.14-local-persistent-volumes-ga/#how-to-use-a-local-persistent-volume)。
    

3. [部署 Local Persistence Volume Static Provisioner](https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner/blob/master/docs/getting-started.md#step-3-creating-local-persistent-volumes)。

4. 查看自动创建的 Local PV。
   
  ```bash
  $ kubectl get pv
  NAME                CAPACITY    ACCESSMODES   RECLAIMPOLICY   STATUS      CLAIM     STORAGECLASS    REASON    AGE
  local-pv-ce05be60   1024220Ki   RWO           Delete          Available             local-storage             26s

  $ kubectl describe pv local-pv-ce05be60
  Name:		local-pv-ce05be60
  Labels:		<none>
  Annotations:	pv.kubernetes.io/provisioned-by=local-volume-provisioner-minikube-18f57fb2-a186-11e7-b543-080027d51893
  StorageClass:	local-storage
  Status:		Available
  Claim:
  Reclaim Policy:	Delete
  Access Modes:	RWO
  Capacity:	1024220Ki
  NodeAffinity:
    Required Terms:
        Term 0:  kubernetes.io/hostname in [my-node]
  Message:
  Source:
      Type:	LocalVolume (a persistent volume backed by local storage on a node)
      Path:	/mnt/disks/vol1
  Events:		<none>
  ```

5. 在集群配置文件中，通过`spec.storaged.dataVolumeClaims`或`spec.metad.dataVolumeClaim`定义的 PVC 和 StorageClass 来绑定 Local PV。具体操作步骤，参见[创建{{nebula.name}}集群](../4.1.installation/4.1.1.cluster-install.md)。
  

##  Local PV 的故障转移

使用网络存储（如 AWS EBS、Google Cloud Persistent Disk、Azure Disk Storage、Ceph、NFS 等）作为 PV，存储资源不依赖于任何特定节点，因此无论 Pod 被调度到哪个节点，都能挂载并使用此存储资源。然而，使用本地存储盘作为 PV 时，由于[节点亲和性（NodeAffinity）](https://kubernetes.io/blog/2018/04/13/local-persistent-volumes-beta/#creating-a-local-persistent-volume)，存储资源只能被特定节点上的 Pod 使用。

{{nebula.name}}的 Storage 服务具备数据冗余能力，可以设置多个奇数分片副本。节点故障时，关联分片会自动迁移到健康节点。但是，使用 Local PV 的 Storage Pod 由于节点亲和性，不能在其他节点运行，必须等待节点恢复。若要在其他节点运行，需要解除 Pod 与 Local PV 的绑定。

针对使用 Local PV 过程中发生节点故障的情况，NebulaGraph Operator 支持进行自动故障转移操作。通过在集群的配置文件中设置`spec.enableAutoFailover`为`true`，自动解除 Pod 与 Local PV 的绑定，从而使 Pod 能在其他节点上运行。

示例如下：

```yaml
...
spec:
  # 开启自动故障转移
  enableAutoFailover: true
  # Storage 服务为`OFFLINE`状态后等待自动故障转移的时间。
  # 默认值 5 分钟。
  # 如果 Storage 服务在此期间内恢复正常状态，不会触发故障转移。
  failoverPeriod: "2m"
  ...
```