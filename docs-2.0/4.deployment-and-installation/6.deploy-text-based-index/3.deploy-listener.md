# Deploy Raft Listener for Nebula Storage service

Full-Text index data is written to the Elasticsearch cluster asynchronously. The Raft Listener (hereinafter shortened as Listener) is a separate process that fetches data from the Storage Service and writes them into the Elasticsearch cluster.

## Prerequisites

* You have read and fully understand the [restrictions](../../4.deployment-and-installation/6.deploy-text-based-index/1.text-based-index-restrictions.md) for using Full-Text indexes.

* You have [deployed a Nebula Graph cluster](../deploy-nebula-graph-cluster.md).

* You have prepared at least one extra Storage Server. To use the Full-Text search, you must run one or more Storage Server as the Raft Listener.

## Precautions

* The Storage Service that you want to run as a Listener must have the same or later version with all the other NebulaÂ Graph services in the cluster.

* For now, you can only add Listeners to a graph space once and for all. Trying to add listeners to a graph space that already has a listener will fail. To add multiple listeners, set them [in one statement](#step_3_add_listeners_to_nebula_graph).

## Step 1: Prepare the configuration file for the Listeners

You have to prepare a Listener configuration file as follows on the machine that you want to deploy the Listeners. The file name must be `nebula-storaged-listener.conf`. A template [configuration file](https://github.com/vesoft-inc/nebula-storage/blob/master/conf/nebula-storaged-listener.conf.production) is provided for your reference. To use the template configuration file, rename it as `nebula-storaged-listener.conf`.

> **NOTE:** Use real IP addresses in the configuration file instead of domain names or loopback IP addresses such as 127.0.0.1.

```conf
########## basics ##########
# Whether to run as a daemon process
--daemonize=true
# The file to host the process id
--pid_file=pids_listener/nebula-storaged.pid

########## logging ##########
# The directory to host logging files, which must already exist
--log_dir=logs_listener
# Log level, 0, 1, 2, 3 for INFO, WARNING, ERROR, FATAL respectively
--minloglevel=0
# Verbose log level, 1, 2, 3, 4, the higher of the level, the more verbose of the logging
--v=0
# Maximum seconds to buffer the log messages
--logbufsecs=0
# Whether to redirect stdout and stderr to separate output files
--redirect_stdout=true
# Destination filename of stdout and stderr, which will also reside in log_dir.
--stdout_log_file=storaged-stdout.log
--stderr_log_file=storaged-stderr.log
# Copy log messages at or above this level to stderr in addition to logfiles. The numbers of severity levels INFO, WARNING, ERROR, and FATAL are 0, 1, 2, and 3, respectively.
--stderrthreshold=2

########## networking ##########
# Meta server address
--meta_server_addrs=192.168.2.1:45500
# Local ip
--local_ip=192.168.2.4
# Storage daemon listening port
--port=44510
# HTTP service ip
--ws_ip=192.168.2.4
# HTTP service port
--ws_http_port=12021
# HTTP2 service port
--ws_h2_port=12031
# heartbeat with meta service
--heartbeat_interval_secs=10

########## storage ##########
# Listener wal directory. only one path is allowed.
--listener_path=data/listener
# This parameter can be ignored for compatibility. let's fill A default value of "data"
--data_path=data
# The type of part manager, [memory | meta]
--part_man_type=memory
# The default reserved bytes for one batch operation
--rocksdb_batch_size=4096
# The default block cache size used in BlockBasedTable.
# The unit is MB.
--rocksdb_block_cache=4
# The type of storage engine, `rocksdb', `memory', etc.
--engine_type=rocksdb
# The type of part, `simple', `consensus'...
--part_type=simple
```

## Step 2: Start the Listeners

Run the following command to start the Listeners.

```bash
./bin/nebula-storaged --flagfile ${listener_config_path}/nebula-storaged-listener.conf
```

`${listener_config_path}` is the path where you store the Listener configuration file.

## Step 3: Add Listeners to Nebula Graph

[Connect to Nebula Graph](../../2.quick-start/3.connect-to-nebula-graph.md) and run [`USE <space>`](../../3.ngql-guide/9.space-statements/2.use-space.md) to enter the graph space that you want to create Full-Text indexes for. Then run the following statement to add the Listener into Nebula Graph.

> **NOTE:** You must use real IPs for the listeners.

```ngql
ADD LISTENER ELASTICSEARCH <listener_ip:port> [,<listener_ip:port>, ...]
```

Multiple `listener_ip:port` pairs are separated with commas. For example:

```ngql
nebula> ADD LISTENER ELASTICSEARCH 192.168.8.5:46780,192.168.8.6:46780;
```

## Show Listeners

Run the `SHOW LISTENER` statement to list the Listeners.

For example:

```ngql
nebula> SHOW LISTENER;
+--------+-----------------+-----------------------+----------+
| PartId | Type            | Host                  | Status   |
+--------+-----------------+-----------------------+----------+
| 1      | "ELASTICSEARCH" | "[192.168.8.5:46780]" | "ONLINE" |
+--------+-----------------+-----------------------+----------+
| 2      | "ELASTICSEARCH" | "[192.168.8.5:46780]" | "ONLINE" |
+--------+-----------------+-----------------------+----------+
| 3      | "ELASTICSEARCH" | "[192.168.8.5:46780]" | "ONLINE" |
+--------+-----------------+-----------------------+----------+
```

## Remove Listeners

Run the `REMOVE LISTENER ELASTICSEARCH` statement to remove all the Elasticsearch Listeners for a graph space.

For example:

```ngql
nebula> REMOVE LISTENER ELASTICSEARCH;
```

## What to do next

After deploying the [Elasticsearch cluster](2.deploy-es.md) and the Listeners, Full-Text indexes are created automatically on the Elasticsearch cluster. You can do Full-Text search now. For more information, see [Full-Text search](../../3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index.md).
