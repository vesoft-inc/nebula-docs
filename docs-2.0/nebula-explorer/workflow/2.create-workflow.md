# Workflow example

This topic describes how to create a simple workflow.

## Prerequisites

- The data source is ready. The data source can be data in NebulaGraph or CSV files on NFS/HDFS.

- The [resource](1.prepare-resources.md) has been configured.

## Add workflow

With the result of the MATCH statement `MATCH (v1:player)--(v2)  RETURN id(v1), id(v2);` as the input of the PageRank algorithm, the following will introduce how to create a simple workflow.

1. At the top of the Explorer page, click **Workflow**.

2. In the **Workflows** tab, click **New workflow** to enter the process canvas page.

3. In the component library list on the left side of the process canvas page, select **Query**->**Query** and drag it onto the canvas. Click the graph query component and set the following parameters in the configuration panel on the right side.

  ![query-component](https://docs-cdn.nebula-graph.com.cn/figures/ex-query-220623-en.png)

  |Parameters|Description|
  |:---|:---|
  |Query|Click ![pencil](https://docs-cdn.nebula-graph.com.cn/figures/workflow-edit.png) to modify the component name to identify the component.|
  |Input| Set custom parameters that can be used for parameterized query. Click **Add parameter** to add more custom parameters. |
  |Query language| Select the graph space to execute the nGQL statement and fill in the nGQL statement. Click **Parse Parameter** to display the returned column name in the **Output**.|
  |Output| The column name returned by parsing the query language. You can change the name, which is equivalent to aliasing the column with `AS`.|
  |Results| Set the saving project of the result. To call the results expediently for other algorithms, the results of the graph query component can be saved in the NFS or HDFS.|

  !!! note

        The connection anchors are shown in yellow, indicating that it is optional and can be set by user or provided by any other component.

4. In the component library list on the left side of the process canvas page, select **Node importance**->**PageRank** and drag it onto the canvas. Connect the anchor `output0` to the anchor `input0` and the anchor `output1` to the anchor `input1`.

  ![connect-component](https://docs-cdn.nebula-graph.com.cn/figures/ex-connect-220623-cn.png)

  If you use multiple graph query components in series, you need to add parameterized text. For example, if you fill in the statement `GO FROM ${id} OVER follow YIELD dst(vertex)` and click `Parse parameter`, a yellow anchor for `${id}` will appear in the graph query component. The output anchor of the previous graph query component can be connected to the yellow anchor as input.

  ![quert-query](https://docs-cdn.nebula-graph.com.cn/figures/query_query_221014_en.png)

5. Click the graph computing component and set the following parameters in the configuration panel on the right side.

  ![connect-component](https://docs-cdn.nebula-graph.com.cn/figures/ex-algorithm-230423-en.png)

  |Parameters|Description|
  |:---|:---|
  |PageRank|Click ![pencil](https://docs-cdn.nebula-graph.com.cn/figures/workflow-edit.png) to modify the component name to identify the component.|
  |Input| Multiple data sources are supported as input. <br>**NebulaGraph**: Users must select one graph space and corresponding edge types.<br>**Dependence**: The system will automatically recognize the data source according to the connection of the anchor.<br>**HDFS**: Users must select HDFS and fill in the relative path of the data source file.<br>**Local**: Users must fill in the relative path of the data source file.|
  |Parameter settings| Set the parameters of the graph algorithm. The parameters of different algorithms are different. Some parameters can be obtained from any upstream component where the anchor are shown in yellow.|
  |Output| Display the column name of the graph computing results. The name can not be modified.|
  |Execution settings| **Machine num**: The number of machines executing the algorithm.<br>**Processes**: The total number of processes executing the algorithm. Allocate these processes equally to each machine based on the number of machines.<br>**Threads**: How many threads are started per process.|
  |Results| Set the restoration path of the results in NFS, HDFS or NebulaGraph.<br>**Local**: The save path is automatically generated based on the job and task ID.<br>**HDFS**: The save path is automatically generated based on the job and task ID.<br>**NebulaGraph**: Tags need to be created beforehand in the corresponding graph space to store the results. For more information about the properties of the tag, see [Algorithm overview](../../graph-computing/algorithm-description.md).<br>Some algorithms can only be saved in the HDFS.|

6. Click ![pencil](https://docs-cdn.nebula-graph.com.cn/figures/workflow-edit.png) next to the automatically generated workflow name at the upper left corner of the canvas page to modify the workflow name, and click **Run** at the upper right corner of the canvas page. The job page is automatically displayed to show the job progress. You can view the result after the job is completed. For details, see [Job management](4.jobs-management.md).

  !!! note

        When you click **Run**, the workflow will be automatically saved. If you do not perform graph computing and only make modifications, click ![save](https://docs-cdn.nebula-graph.com.cn/figures/workflow-save-220623.png) to save the modification, or click ![save](https://docs-cdn.nebula-graph.com.cn/figures/workflow-saveAs-220623.png) to save the workflow as a new workflow.
