# Deploy NebulaGraph clusters with Kubectl

!!! Compatibility "Legacy version compatibility"

    The 1.x version NebulaGraph Operator is not compatible with NebulaGraph of version below v3.x.

## Prerequisites

- [You have installed NebulaGraph Operator](../2.deploy-nebula-operator.md)

- [You have created StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/)
  
{{ ent.ent_begin }}

- [LM has been installed and the License Key has been successfully loaded](3.0.deploy-lm.md) (Enterprise only)

{{ ent.ent_end }}

## Create clusters

The following example shows how to create a NebulaGraph cluster by creating a cluster named `nebula`.

1. Create a namespace, for example, `nebula`. If not specified, the `default` namespace is used.

  ```bash
  kubectl create namespace nebula
  ```

  {{ent.ent_begin}}
2. Create a Secret for pulling the NebulaGraph Enterprise image from a private repository.

  !!! note
        Skip this step if you are using NebulaGraph Community Edition.

  ```bash
  kubectl -n <nebula> create secret docker-registry <image-pull-secret> \
  --docker-server=DOCKER_REGISTRY_SERVER \
  --docker-username=DOCKER_USER \
  --docker-password=DOCKER_PASSWORD
  ```

  - `<nebula>`: The namespace where this Secret will be stored.
  - `<image-pull-secret>`: Specify the name of the Secret.
  - `DOCKER_REGISTRY_SERVER`: Specify the server address of the private repository from which the image will be pulled, such as `reg.example-inc.com`.
  - `DOCKER_USER`: The username for the image repository.
  - `DOCKER_PASSWORD`: The password for the image repository.

  {{ent.ent_end}}

3. Create a file named `apps_v1alpha1_nebulacluster.yaml`.

  - For a NebulaGraph Community cluster
  
    For the file content, see the [sample configuration](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/config/samples/apps_v1alpha1_nebulacluster.yaml).

    ??? Info "Expand to show sample parameter descriptions"

        | Parameter    | Default value  | Description    |
        | :---- | :--- | :--- |
        | `metadata.name`              | -                                                            | The name of the created NebulaGraph cluster. |
        | `spec.graphd.replicas`       | `1`                                                          | The numeric value of replicas of the Graphd service.         |
        | `spec.graphd.image`         | `vesoft/nebula-graphd`                                       | The container image of the Graphd service.      |
        | `spec.graphd.version`        | `{{nebula.tag}}`                                          | The version of the Graphd service.         |
        | `spec.graphd.service`        | -                                                            | The Service configurations for the Graphd service.      |
        | `spec.graphd.logVolumeClaim.storageClassName`   | -                                         | The log disk storage configurations for the Graphd service.         |
        | `spec.metad.replicas`        | `1`                                                          | The numeric value of replicas of the Metad service.          |
        | `spec.metad.image`          | `vesoft/nebula-metad`                                        | The container image of the Metad service.        |
        | `spec.metad.version`         | `{{nebula.tag}}`                                          | The version of the Metad service.          |
        | `spec.metad.dataVolumeClaim.storageClassName`    | -                                        | The data disk storage configurations for the Metad service.          |
        | `spec.metad.logVolumeClaim.storageClassName`|-                                              | The log disk storage configurations for the Metad service.|
        | `spec.storaged.replicas`     | `3`                                                          | The numeric value of replicas of the Storaged service.       |
        | `spec.storaged.image`       | `vesoft/nebula-storaged`                                     | The container image of the Storaged service.     |
        | `spec.storaged.version`      | `{{nebula.tag}}`                                          | The version of the Storaged service.       |
        | `spec.storaged.dataVolumeClaims.resources.requests.storage` | - | Data disk storage size for the Storaged service. You can specify multiple data disks to store data. When multiple disks are specified, the storage path is `/usr/local/nebula/data1`, `/usr/local/nebula/data2`, etc.|
        | `spec.storaged.dataVolumeClaims.resources.storageClassName` | - | The data disk storage configurations for Storaged. If not specified, the global storage parameter is applied. |
        | `spec.storaged.logVolumeClaim.storageClassName`|-                                           | The log disk storage configurations for the Storaged service.|
        | `spec.storaged.enableAutoBalance` | `true` |Whether to balance data automatically. |
        |`spec.agent`|`{}`| Configuration of the Agent service. This is used for backup and recovery as well as log cleanup functions. If you do not customize this configuration, the default configuration will be used.|
        | `spec.reference.name`        | -                                                            | The name of the dependent controller.           |
        | `spec.schedulerName`         | -                                                            | The scheduler name.                 |
        | `spec.imagePullPolicy`       | The image policy to pull the NebulaGraph image. For details, see [Image pull policy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy). | The image pull policy in Kubernetes.               |
        |`spec.logRotate`| - |Log rotation configuration. For more information, see [Manage cluster logs](../8.custom-cluster-configurations/8.4.manage-running-logs.md).|
        |`spec.enablePVReclaim`|`false`|Define whether to automatically delete PVCs and release data after deleting the cluster. For more information, see [Reclaim PVs](../8.custom-cluster-configurations/8.2.pv-reclaim.md).|

  {{ ent.ent_begin }}

  - For a NebulaGraph Enterprise cluster

    Contact our sales team to get a complete NebulaGraph Enterprise Edition cluster YAML example.

    !!! enterpriseonly

        Make sure that you have access to NebulaGraph Enterprise Edition images before pulling the image. 

    === "Cluster without Zones"

        You must set the following parameters in the configuration file for the enterprise edition. Other parameters can be changed as needed. For information on other parameters, see the [sample configuration](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/config/samples/apps_v1alpha1_nebulacluster.yaml). 


        | Parameter    | Default value  | Description    |
        | :---- | :--- | :--- |
        | `spec.metad.licenseManagerURL` | - | Configure the URL that points to the LM, which consists of the access address and port number (default port `9119`) of the LM. For example, `192.168.8.100:9119`. **You must configure this parameter in order to obtain the license information; otherwise, the enterprise edition cluster cannot be used.** |
        |`spec.<graphd|metad|storaged>.image`|-|The container image of the Graph, Meta, or Storage service of the enterprise edition.|
        |`spec.imagePullSecrets`| - |Specifies the Secret for pulling the NebulaGraph Enterprise service images from a private repository.|


    === "Cluster with Zones"

        NebulaGraph Operator supports creating a cluster with [Zones](../../4.deployment-and-installation/5.zone.md). You need to set the following parameters for creating a cluster with Zones are as follows. Other parameters can be changed as needed. For more information on other parameters, see the [sample configuration](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/config/samples/apps_v1alpha1_nebulacluster.yaml). 


        | Parameter    | Default value  | Description    |
        | :---- | :--- | :--- |
        | `spec.metad.licenseManagerURL` | - | Configure the URL that points to the LM, which consists of the access address and port number (default port `9119`) of the LM. For example, `192.168.8.100:9119`. **You must configure this parameter in order to obtain the license information; otherwise, the enterprise edition cluster cannot be used.** |
        |`spec.<graphd|metad|storaged>.image`|-|The container image of the Graph, Meta, or Storage service of the enterprise edition.|
        |`spec.imagePullSecrets`| - |Specifies the Secret for pulling the NebulaGraph Enterprise service images from a private repository.|
        |`spec.alpineImage`|`reg.vesoft-inc.com/nebula-alpine:latest`|The Alpine Linux image, used to obtain the Zone information where nodes are located.| 
        |`spec.metad.config.zone_list`|-|A list of zone names, split by comma.|
        |`spec.graphd.config.enable_intra_zone_routing`|`false`|Specifies whether to prioritize sending queries to the storage nodes in the same zone.<br/>When set to `true`, the query is sent to the storage nodes in the same zone. If no data is available in that Zone, it will decide based on `stick_to_intra_zone_on_failure` whether to read data from other Zones. |
        |`spec.graphd.config.stick_to_intra_zone_on_failure`|`false`|Specifies whether to stick to intra-zone routing if unable to find the requested partitions in the same zone. When set to `true`, if no data is available in that Zone, it does not read data from other Zones.|

        ??? Info "Expand to see partial configurations"

            ```yaml
            apiVersion: apps.nebula-graph.io/v1alpha1
            kind: NebulaCluster
            metadata:
              name: nebula
              namespace: default
            spec:
              # Alpine image built with linux tools.
              alpineImage: "reg.vesoft-inc.com/nebula-alpine:latest"
              graphd:
                config:
                  # Prioritize sending queries to the storage nodes in the same zone.
                  enable_intra_zone_routing: "true"
                  # Stick to intra-zone routing if unable to
                  # find the requested part in the zone when set to true.
                  stick_to_intra_zone_on_failure: "true"
                ...
              metad:
                config:
                  # A list of zones, split by comma
                  zone_list: az1,az2,az3
                licenseManagerURL: "192.168.8.53:9119"
                ...  
            ```

    Other optional parameters for the enterprise edition are as follows:

    | Parameter    | Default value  | Description    |
    | :---- | :--- | :--- |
    |`spec.storaged.enableAutoBalance`| `false`| Specifies whether to enable automatic data balancing. For more information, see [Balance storage data after scaling out](../8.custom-cluster-configurations/8.3.balance-data-when-scaling-storage.md).|
    |`spec.enableBR`|`false`|Specifies whether to enable the BR tool. For more information, see [Backup and restore](../10.backup-restore-using-operator.md).|



  {{ ent.ent_end }}

1. Create a NebulaGraph cluster.

  ```bash
  kubectl create -f apps_v1alpha1_nebulacluster.yaml
  ```

  Output:

  ```bash
  nebulacluster.apps.nebula-graph.io/nebula created
  ```

5. Check the status of the NebulaGraph cluster.
   
  ```bash
  kubectl get nebulaclusters.apps.nebula-graph.io nebula
  ```

  Output:

  ```bash
  NAME     GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE
  nebula   1                1              1               1             3                  3                86s
  ```

## Scaling clusters

- The cluster scaling feature is for NebulaGraph Enterprise Edition only. 

{{ ent.ent_begin }}

- Scaling a NebulaGraph cluster for Enterprise Edition is supported only with NebulaGraph Operator version 1.1.0 or later. 

You can modify the value of `replicas` in `apps_v1alpha1_nebulacluster.yaml` to scale a NebulaGraph cluster.

### Scale out clusters

The following shows how to scale out a NebulaGraph cluster by changing the number of Storage services to 5:

1. Change the value of the `storaged.replicas` from `3` to `5` in `apps_v1alpha1_nebulacluster.yaml`.

  ```yaml
    storaged:
      resources:
        requests:
          cpu: "500m"
          memory: "500Mi"
        limits:
          cpu: "1"
          memory: "1Gi"
      replicas: 5
      image: vesoft/nebula-storaged
      version: {{nebula.tag}}
      dataVolumeClaims:
      - resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
      - resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
      logVolumeClaim:
        resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
    reference:
      name: statefulsets.apps
      version: v1
    schedulerName: default-scheduler
  ```

2. Run the following command to update the NebulaGraph cluster CR.

  ```bash
  kubectl apply -f apps_v1alpha1_nebulacluster.yaml
  ```
  
3. Check the number of Storage services.

  ```bash
  kubectl get pods -l app.kubernetes.io/cluster=nebula
  ```

  Output:

  ```bash
  NAME                READY   STATUS    RESTARTS   AGE
  nebula-graphd-0     1/1     Running   0          2m
  nebula-metad-0      1/1     Running   0          2m
  nebula-storaged-0   1/1     Running   0          2m
  nebula-storaged-1   1/1     Running   0          2m
  nebula-storaged-2   1/1     Running   0          2m
  nebula-storaged-3   1/1     Running   0          5m
  nebula-storaged-4   1/1     Running   0          5m
  ```

  As you can see above, the number of Storage services is scaled up to 5.

### Scale in clusters

The principle of scaling in a cluster is the same as scaling out a cluster. You scale in a cluster if the numeric value of the `replicas` in `apps_v1alpha1_nebulacluster.yaml` is changed smaller than the current number. For more information, see the **Scale out clusters** section above.

!!! caution

    NebulaGraph Operator currently only supports scaling Graph and Storage services and does not support scale Meta services.

{{ ent.ent_end }}

## Delete clusters

Run the following command to delete a NebulaGraph cluster with Kubectl:

```bash
kubectl delete -f apps_v1alpha1_nebulacluster.yaml
```

## What's next

[Connect to NebulaGraph databases](../4.connect-to-nebula-graph-service.md)
