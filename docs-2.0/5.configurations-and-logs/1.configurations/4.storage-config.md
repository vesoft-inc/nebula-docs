# Storage Service configurations

This document gives some introductions to Storage Service configurations. Storage Service configurations are stored in `nebula-storaged.conf.default` and `nebula-storaged.conf.production`. The configuration files are stored in `/usr/local/nebula/etc/` by default. If you have customized your Nebula Graph installation directory, the path to your configuration files is `$pwd/nebula/etc/`.

> **NOTE:** Raft Listener is different from the Storage Service. For more information, see [Raft Listener](../../4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener.md).

* The `nebula-storaged.conf.default` file is the **default configuration file** for the Storage Service. We suggest that you use it for **debugging**. When you start Nebula Graph for the first time, Nebula Graph uses the default configuration files.
* The `nebula-storaged.conf.production` file is the **production configuration file** for the Storage Service. We suggest that you use it for the **production environment**. To use it, you must remove the `.production` suffix.

> **NOTE:** To change these parameters, you must add `--local_conf=true` at the top of the configuration file.

## Basic configurations

| Name        | Default Value           | Descriptions                                         |
| ----------- | ----------------------- | ---------------------------------------------------- |
| `daemonize` | `true`                    | When set to `true`, the process is a daemon process. |
| `pid_file`  | `pids/nebula-storaged.pid` | File to host the process ID.                         |

## Logging configurations

| Name          | Default Value            | Descriptions                                                                                                                                                                                                                                                            |
| ------------- | ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `log_dir`     | `logs` | Directory to the Storage Service log. We recommend that you put logs on a different hard disk from the `data_path`.                                                                                                                                                        |
| `minloglevel` | `0`                      | Specifies the minimum log level. Available values are 0-3. `0`, `1`, `2`, and `3` are `INFO`, `WARNING`, `ERROR`, and `FATAL`. We suggest that you set `minloglevel` to `0` for debug, `1` for production. When you set it to `4`, Nebula Graph does not print any logs. |
| `v`           | `0`                      | Specifies the verbose log level. Available values are 0-4. The larger the value, the more verbose the log.                                                                                                                                                              |
| `logbufsecs`  | `0`                      | Specifies the maximum time to buffer the logs. The configuration is measured in seconds.                                                                                                                                                                                |
|`redirect_stdout` | `true` | When set to `true`, stdout and stderr are redirected.
`stdout_log_file`               |`storaged-stdout.log`              | Specifies the filename for the stdout log.
`stderr_log_file`               | `storaged-stderr.log`| Specifies the filename for the stderr log.
`stderrthreshold`         | `2`     | Specifies the minimum level to copy the log messages to stderr. Available values are 0-3. `0`, `1`, `2`, and `3` are `INFO`, `WARNING`, `ERROR`, and `FATAL`. |

## Networking configurations

| Name                      | Default Value    | Descriptions                                                                                                                                                 |
| ------------------------- | ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `meta_server_addrs`       | `127.0.0.1:9559` | Specifies the IP addresses for the Meta Services. Multiple addresses are permitted, separated by commas.                                                  |
`local_ip`                      | `127.0.0.1`   | Specifies the local IP for the Storage Service.  |
| `port`                    | `9779`            | Specifies RPC daemon listening port. The external port for Storage Service is `9669`. The internal port is `port+1`, namely `9670`. Nebula Graph uses the internal port for multi-replica interactions. |
| `ws_ip`                   | `0.0.0.0`    | Specifies the IP address for the HTTP service.                                                                                                                                        |
| `ws_http_port`            | `19779`            | Specifies the port for the HTTP service.                                                   |
| `ws_h2_port`              | `19780`            | Specifies the port for the HTTP2 service.                     |
|

> **NOTE**: We recommend that you use the real IP address in your configuration because sometimes `127.0.0.1` can not be parsed correctly.

## Raft configurations

| Name        | Default Value                                 | Descriptions                               |
| ----------- | --------------------------------------------- | ------------------------------------------ |
| `raft_heartbeat_interval_secs` | `30` | Specifies the timeout for the Raft election. The configuration is measured in seconds.|
| `raft_rpc_timeout_ms` | `500` | Specifies the timeout for the Raft RPC. The configuration is measured in milliseconds.|
| `wal_ttl`                           | `14400` | Specifies the recycle RAFT wal time. The configuration is measured in seconds.                                               |

## Disk configurations

| Property        | Default Value           | Descriptions                |
| ----------- | --------------------------------------------------- | -------------------------------------------------------- |
| `data_path` | `data/storage`  |  Specifies the root data path. Multiple paths are permitted, separated commas. |
| `rocksdb_batch_size`                | `4096`   | Specifies the block cache for a batch operation. The configuration is measured in bytes. |
| `rocksdb_block_cache`               | `4`  | Specifies the block cache for BlockBasedTable. The configuration is measured in megabytes.|
| `engine_type` | `rocksdb` | Specifies the engine type. |
| `rocksdb_compression` | `snappy` | Specifies the compression algorithm for RocksDB. Available values are `no`, `snappy`, `lz4`, `lz4hc`, `zlib`, `bzip2`, and `zstd`. |
| `rocksdb_compression_per_level` | \ | Specifies compression for each level. |
| `rocksdb_stats_level` | `kExceptHistogramOrTimers` | Specifies the stats level for RocksDB. Available values are `kExceptHistogramOrTimers`, `kExceptTimers`, `kExceptDetailedTimers`, `kExceptTimeForMutex`, and `kAll`. |
| `enable_rocksdb_prefix_filtering` | `false` | When set to `true`, the prefix bloom filter for RocksDB is enabled. |
| `rocksdb_filtering_prefix_length` | `12` | Specifies the prefix length for each key. Available values are `12` and `16`. |

## RocksDB configurations

| Property        | Default Value           | Descriptions                |
| ----------- | --------------------------------------------------- | -------------------------------------------------------- |
| `rocksdb_disable_wal` | `true` | When set to `true`, RocksDB wal is enabled. |
| `rocksdb_db_options` | \ | Specifies the RocksDB options. Multiple options are permitted, separated with commas. For more information, see the next section. |
| `rocksdb_column_family_options` | \ | Specifies the RocksDB column family options. Multiple options are permitted, separated with commas. For more information, see the next section. |
| `rocksdb_block_based_table_options` | `"block_size":"8192"` | Specifies the RocksDB block based table options. Multiple options are permitted, separated with commas. For more information, see the next section. |

### `rocksdb_db_options`

```text
max_total_wal_size
delete_obsolete_files_period_micros
max_background_jobs
stats_dump_period_sec
compaction_readahead_size
writable_file_max_buffer_size
bytes_per_sync
wal_bytes_per_sync
delayed_write_rate
avoid_flush_during_shutdown
max_open_files
stats_persist_period_sec
stats_history_buffer_size
strict_bytes_per_sync
enable_rocksdb_prefix_filtering
enable_rocksdb_whole_key_filtering
rocksdb_filtering_prefix_length
num_compaction_threads
rate_limit
```

### `rocksdb_column_family_options`

```text
write_buffer_size
max_write_buffer_number
level0_file_num_compaction_trigger
level0_slowdown_writes_trigger
level0_stop_writes_trigger
target_file_size_base
target_file_size_multiplier
max_bytes_for_level_base
max_bytes_for_level_multiplier
disable_auto_compactions       -- Compact automatically when writing data is stopped, default value is false. Dynamic modification takes effect immediately.

```

<!--
## For super-Large vertices

For super vertex with a large number of edges, currently there are two truncation strategies:

1. Truncate directly. Set the `enable_reservoir_sampling` parameter to `false`. A certain number of edges specified in the `Max_edge_returned_per_vertex` parameter are truncated by default.

2. Truncate with the reservoir sampling algorithm. Based on the algorithm, a certain number of edges specified in the `Max_edge_returned_per_vertex` parameter are truncated with equal probability from the total n edges. Equal probability sampling is useful in some business scenarios. However, the performance is effected compared to direct truncation due to the probability calculation. -->

## Storage configuration for large dataset

When you have a large dataset (in the RocksDB directory) and your memory is tight, we suggest that you set the `enable_partitioned_index_filter` parameter to `true`. For example, 100 vertices + 100 edges require 300 key-values. Each key takes 10bit in memory. Then you can calculate your own memory usage.
