# Use BR to restore data

If you use the BR to back up data, you can use it to restore the data to NebulaGraph. This topic introduces how to use the BR to restore data from backup files.

!!! caution

    During the restoration process, the data on the target NebulaGraph cluster is removed and then is replaced with the data from the backup files. If necessary, back up the data on the target cluster.

!!! caution

    The restoration process is performed OFFLINE.

## Prerequisites

- [Install BR and Agent](2.compile-br.md) and run Agent on each host in the cluster. 

- No application is connected to the target NebulaGraph cluster.

- Make sure that the target and the source NebulaGraph clusters have the same topology, which means that they have exactly the same number of hosts. The number of data folders for each host is consistently distributed.

## Procedures

In the BR installation directory (the default path of the compiled BR is `./br`), run the following command to perform a full backup for the entire cluster.

1. Users can use the following command to list the existing backup information:

  ```bash
  $ ./br show --storage <storage_path>
  ```
  For example, run the following command to list the backup information in the local `/home/nebula/backup` path.
  ```bash
  $ ./br show --storage "local:///home/nebula/backup"
  +----------------------------+---------------------+------------------------+-------------+------------+
  |            NAME            |     CREATE TIME     |         SPACES         | FULL BACKUP | ALL SPACES |
  +----------------------------+---------------------+------------------------+-------------+------------+
  | BACKUP_2022_02_10_07_40_41 | 2022-02-10 07:40:41 | basketballplayer       | true        | true       |
  | BACKUP_2022_02_11_08_26_43 | 2022-02-11 08:26:47 | basketballplayer,foesa | true        | true       |
  +----------------------------+---------------------+------------------------+-------------+------------+
  ```

  Or, you can run the following command to list the backup information stored in S3 URL `s3://192.168.8.129:9000/br-test/backup`.
  ```bash
  $ ./br show --s3.endpoint "http://192.168.8.129:9000" --storage="s3://br-test/backup/" --s3.access_key=minioadmin --s3.secret_key=minioadmin --s3.region=default
  ```

  | Parameter    | Data type | Required | Default value | Description                                                                 |
  | ---          | ---      | ---           | ---                                                                         | ---       |
  | `-h,-help`     | -         | No       | None          | Checks help for restoration.                                                |
  | `-debug` | - | No | None | Checks for more log information. |
  | `-log`        | string    | No       | `"br.log"`        | Specifies detailed log path for restoration and backup. | 
  | `--storage` | string | Yes | None | The target storage URL of BR backup data. The format is: <Schema\>://<PATH\>. <br>Schema: Optional values are `local` and `s3`. <br>When selecting s3, you need to fill in `s3.access_key`, `s3.endpoint`, `s3.region`, and `s3.secret_key`.<br>PATH: The path of the storage location. |
  | `--s3.access_key` | string | No | None | Sets AccessKey ID. |
  | `--s3.endpoint` | string | No | None | Sets the S3 endpoint URL, please specify the HTTP or HTTPS scheme explicitly. |
  | `--s3.region` | string | No | None | Sets the region or location to upload or download the backup. |
  | `--s3.secret_key` | string | No | None | Sets SecretKey for AccessKey ID. |


2. Run the following command to restore data.

  ```
  $ ./br restore full --meta <ip_address> --storage <storage_path> --name <backup_name>
  ```

  For example, run the following command to upload the backup files from the local `/home/nebula/backup/` to the cluster where the meta service's address is `192.168.8.129:9559`.

  ```
  $ ./br restore full --meta "192.168.8.129:9559" --storage "local:///home/nebula/backup/" --name BACKUP_2021_12_08_18_38_08
  ```

  Or, you can run the following command to upload the backup files from the S3 URL `s3://192.168.8.129:9000/br-test/backup`.
  ```bash
  $ ./br restore full --meta "192.168.8.129:9559" --s3.endpoint "http://192.168.8.129:9000" --storage="s3://br-test/backup/" --s3.access_key=minioadmin --s3.secret_key=minioadmin --s3.region="default" --name BACKUP_2021_12_08_18_38_08
  ```

  If the following information is returned, the data is restored successfully.
  ```bash
  Restore succeed.
  ```

  !!! caution

        If your new cluster hosts' IPs are not all the same as the backup cluster, after restoration, you should run `add hosts` to add the Storage host IPs in the new cluster one by one.

  The parameters are as follows.

  | Parameter    | Data type | Required | Default value | Description                                                                 |
  | ---          | ---      | ---           | ---                                                                         | ---       |
  | `-h,-help`     | -         | No       | None          | Checks help for restoration.                                                |
  | `-debug` | - | No | None | Checks for more log information. |
  | `-log`        | string    | No       | `"br.log"`        | Specifies detailed log path for restoration and backup. |
  | `-meta`        | string    | Yes       | None        | The IP address and port of the meta service. |
  | `-name`        | string    | Yes       | None        | The name of backup. |
  | `--storage` | string | Yes | None | The target storage URL of BR backup data. The format is: \<Schema\>://\<PATH\>. <br>Schema: Optional values are `local` and `s3`. <br>When selecting s3, you need to fill in `s3.access_key`, `s3.endpoint`, `s3.region`, and `s3.secret_key`.<br>PATH: The path of the storage location. |
  | `--s3.access_key` | string | No | None | Sets AccessKey ID. |
  | `--s3.endpoint` | string | No | None | Sets the S3 endpoint URL, please specify the HTTP or HTTPS scheme explicitly. |
  | `--s3.region` | string | No | None | Sets the region or location to upload or download the backup. |
  | `--s3.secret_key` | string | No | None | Sets SecretKey for AccessKey ID. |

3. Run the following command to clean up temporary files if any error occurred during backup. It will clean the files in cluster and external storage. You could also use it to clean up old backups files in external storage.

  ```bash
  $ ./br cleanup --meta <ip_address> --storage <storage_path> --name <backup_name>
  ```

  The parameters are as follows.

  | Parameter    | Data type | Required | Default value | Description                                                                 |
  | ---          | ---      | ---           | ---                                                                         | ---       |
  | `-h,-help`     | -         | No       | None          | Checks help for restoration.                                                |
  | `-debug` | - | No | None | Checks for more log information. |
  | `-log`        | string    | No       | `"br.log"`        | Specifies detailed log path for restoration and backup. |
  | `-meta`        | string    | Yes       | None        | The IP address and port of the meta service. |
  | `-name`        | string    | Yes       | None        | The name of backup. |
  | `--storage` | string | Yes | None | The target storage URL of BR backup data. The format is: \<Schema\>://\<PATH\>. <br>Schema: Optional values are `local` and `s3`. <br>When selecting s3, you need to fill in `s3.access_key`, `s3.endpoint`, `s3.region`, and `s3.secret_key`.<br>PATH: The path of the storage location. |
  | `--s3.access_key` | string | No | None | Sets AccessKey ID. |
  | `--s3.endpoint` | string | No | None | Sets the S3 endpoint URL, please specify the HTTP or HTTPS scheme explicitly. |
  | `--s3.region` | string | No | None | Sets the region or location to upload or download the backup. |
  | `--s3.secret_key` | string | No | None | Sets SecretKey for AccessKey ID. |
