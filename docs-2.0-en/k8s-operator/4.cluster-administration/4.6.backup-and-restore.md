# Backup and restore data using NebulaGraph Operator

This article introduces how to back up and restore data of the NebulaGraph cluster on Kubernetes.

!!! note

    Make sure that the [zone](../../4.deployment-and-installation/5.zone.md) feature is not enabled in the NebulaGraph cluster before using the backup and restore in Operator, otherwise the backup and restore will fail. For details on zones, see [Cluster with zones](4.8.ha-and-balancing/4.8.2.enable-zone.md).
    
## Overview

[{{br_ent.name}}](../../backup-and-restore/br-ent/1.br-ent-overview.md) is a command line tool for data backup and recovery of NebulaGraph enterprise edition. NebulaGraph Operator utilizes the {{br_ent.name}} tool to achieve data backup and recovery for NebulaGraph clusters on Kubernetes.

When backing up data, NebulaGraph Operator creates a job to back up the data in the NebulaGraph cluster to the specified storage service.

When restoring data, NebulaGraph Operator checks the specified backup NebulaGraph cluster for existence, and whether access to remote storage is allowed based on the information defined in the NebulaRestore resource object. It then creates a new cluster and restores the backup data to the new NebulaGraph cluster. For more information, see [restore flowchart](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/doc/user/br_guide.md#restore-nebulagraph-cluster).

## Prerequisites

To backup and restore data using NebulaGraph Operator, the following conditions must be met:

- NebulaGraph Operator version >= 1.4.0.
- The enterprise edition NebulaGraph cluster deployed on Kubernetes is running.
- In the YAML file used to create the cluster, `spec.enableBR` is set to true. For more information, see [Create a NebulaGraph cluster](4.1.installation/4.1.1.cluster-install.md)

  ```yaml
  // Partial content of a sample cluster YAML file.
  apiVersion: apps.nebula-graph.io/v1alpha1
  kind: NebulaCluster
  metadata:
    name: nebula
  spec:  
    enableBR: true // Set to true to enable the backup and restore function.
  ...
  ```

- Only storage services that use the S3 protocol (such as AWS S3, Minio, etc.) and Google Cloud Storage can be used to back up and restore data.
- Sufficient computing resources are available in the cluster to restore data.

## Backup 

### Notes

- NebulaGraph Operator supports full and incremental backups.
- During data backup, DDL and DML statements in the specified graph space will be blocked. We recommend you perform the operation during off-peak hours, such as from 2:00 am to 5:00 am.
- The cluster executing incremental backups and the cluster specified for the last backup must be the same, and the storage bucket for the last backup must be the same.
- Ensure that the time between each incremental backup and the last backup is less than a [`wal_ttl`](../../5.configurations-and-logs/1.configurations/4.storage-config.md#raft_configurations).
- Specifying the backup data of a specified graph space is not supported.
- Before backing up data, you need to create a Secret to restore the credential for pulling the image of the {{br_ent.name}} tool.
  
  ```bash
  kubectl -n <nebula> create secret docker-registry <br-ent-secret> \
  --docker-server=REGISTRY_SERVER \
  --docker-username=REGISTRY_USERNAME \
  --docker-password=REGISTRY_PASSWORD \
  ```

  - `<nebula>`: The namespace where the Secret is located.
  - `<br-ent-secret>`: The name of the Secret.
  - `REGISTRY_SERVER`: The address of the private image repository server from which the image is pulled, for example, `reg.example-inc.com`.
  - `REGISTRY_USERNAME`: The username for logging in to the private image repository server.
  - `REGISTRY_PASSWORD`: The password for logging in to the private image repository server.

### Full backup

When backing up data to a cloud storage service, you need to create a backup job, which will back up the full NebulaGraph data to the specified storage location.

Here is an example of the YAML file for a full backup job that backs up data to an S3 protocol-compatible storage service:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: nebula-full-backup
spec:
  parallelism: 1
  ttlSecondsAfterFinished: 600
  template:
    spec:
      restartPolicy: OnFailure
      imagePullSecrets:
        - name: br-ent-secret  # The name of the Secret for pulling the image of the {{br_ent.name}} tool.
      containers:
        - image: reg.vesoft-inc.com/cloud-dev/br-ent:v{{br_ent.release}}
          imagePullPolicy: Always
          name: backup
          command:
            - /bin/sh
            - -ecx
            - 'exec /usr/local/bin/br-ent backup full 
            --meta nebula-metad-0.nebula-metad-headless.nebula.svc.cluster.local:9559   # The address of the Metad service. 
            --storage s3://BUCKET_NAME                           # The name of the S3 bucket where the backup data is stored.
            --s3.access_key ACCESS_KEY                      # The AccessKey for accessing the S3 protocol-compatible storage service.
            --s3.secret_key SECRET_KEY                      # The SecretKey for accessing the S3 protocol-compatible storage service.
            --s3.region REGION                              # The region of the S3 protocol-compatible storage service.
            --s3.endpoint https://s3.REGION.amazonaws.com'  # The endpoint of the S3 protocol-compatible storage service.
```

To back up data to Google Cloud Storage, replace the S3-related options with the `--gs.credentials` option and modify the `--storage` option  in the `spec.template.spec.containers[0].command` section accordingly.

Example:

```yaml
...
          command:
            - /bin/sh
            - -ecx
            - 'exec /usr/local/bin/br-ent backup full 
            --meta nebula-metad-0.nebula-metad-headless.nebula.svc.cluster.local:9559   # The address of the Metad service. 
            --storage gs://BUCKET_NAME                          # The name of the GCS bucket where the backup data is stored.
            --gs.credentials '{"type":"service_account","project_id":"<project_id>","project_key":"<project_key>","private_key":"<private_key>","client_email":"<service_account_email>","client_id":"<client_id>","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_x509_cert_url":"https://www.googleapis.com/robot/v1/metadata/x509/<service_account_email>","universe_domain":"googleapis.com"}'# The JSON string that represents your service account key provided by Google Cloud.
```


### Incremental backup

Except for the name of the job and the command specified in `spec.template.spec.containers[0].command`, the YAML file for incremental backup is the same as that for a full backup. Here is an example of the YAML file for incremental backup:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: nebula-incr-backup
spec:
  parallelism: 1
  ttlSecondsAfterFinished: 60
  template:
    spec:
      restartPolicy: OnFailure
      imagePullSecrets:
        - name: br-ent-secret
      containers:
        - image: reg.vesoft-inc.com/cloud-dev/br-ent:v{{br_ent.release}}
          imagePullPolicy: Always
          name: backup
          command:
            - /bin/sh
            - -ecx
            - 'exec /usr/local/bin/br-ent backup incr
            --meta nebula-metad-0.nebula-metad-headless.nebula.svc.cluster.local:9559 # The address of the Metad service. 
            --storage s3://BUCKET_NAME                          # The name of the S3 bucket where the backup data is stored.
            --s3.access_key ACCESS_KEY                      # The AccessKey for accessing the S3 protocol-compatible storage service.
            --s3.secret_key SECRET_KEY                      # The SecretKey for accessing the S3 protocol-compatible storage service.
            --s3.region REGION                              # The region of the S3 protocol-compatible storage service.
            --s3.endpoint https://s3.REGION.amazonaws.com'  # The endpoint of the S3 protocol-compatible storage service.
```

### Parameter description

The main parameters are described as follows:


| Parameter          |Default value | Description |
| ------------- | ---- | ---- |
| `spec.parallelism` |1  |The number of tasks executed in parallel. |
| `spec.ttlSecondsAfterFinished` | 60 | The time to keep task information after the task is completed. |
| `spec.template.spec.containers[0].image` | `vesoft/br-ent:{{br_ent.release}}`|The image address of the {{br_ent.name}} tool. |
| `spec.template.spec.containers[0].command`| - |  The command for backing up data to the storage service compatible with the S3 protocol.<br/>For descriptions of the options in the command, see [Parametr description](../../backup-and-restore/br-ent/3.backup-data.md#_13). |
 

For more settings of the job, see [Kubernetes Jobs](https://kubernetes.io/docs/concepts/workloads/controllers/job/).

After the YAML file for the backup job is set, run the following command to start the backup job:


```bash
kubectl apply -f <backup_file_name>.yaml
```

When the data backup succeeds, a backup file is generated in the specified storage location. For example, the backup file name is `BACKUP_2023_02_12_10_04_16`.

### Encrypted backup

If you enable mTLS authentication for the NebulaGraph cluster, you need to certify the {{br_ent.name}} tool to access the NebulaGraph cluster. To do that, you can either mount the certificate files to the container or configure environment variables to specify the paths to the certificate files.

#### Mount the certificate files to the container

In the YAML file for the backup job, add volumes to store the client certificate files and the CA certificate files, and mount the certificate files to the container. Then add the `--enable-ssl` and `--insecure-skip-verify` options to the command for backing up data. 

!!! note

    Create Secrets to store the certificate files before creating the backup job, and make sure the Secrets are in the namespace where the backup job is located. For details, see [Enable mTLS in NebulaGraph](4.7.security/4.7.1.enable-mtls.md).

The following YAML file creates a full backup job that mounts the certificate files to the container:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: nebula-full-backup
spec:
  parallelism: 1
  ttlSecondsAfterFinished: 600
  template:
    spec:
      restartPolicy: OnFailure
      imagePullSecrets:
        - name: nebula-image
      containers:
        - image: reg.vesoft-inc.com/cloud-dev/br-ent:v3.5.1
          imagePullPolicy: Always
          name: backup
          command:
            - /bin/sh
            - -ecx
            - 'exec /usr/local/bin/br-ent backup full 
            --meta META_ADDRESS:9559 
            --storage s3://BUCKET_NAME
            --s3.access_key ACCESS_KEY 
            --s3.secret_key SECRET_KEY 
            --s3.region REGION 
            --s3.endpoint https://s3.REGION.amazonaws.com
            --enable-ssl                                      # Enable mTLS authentication.
            --insecure-skip-verify'                           # Skip the verification of the server's certificate chain and hostname.
          volumeMounts:                                       # Mount the certificate files.              
            - mountPath: /usr/local/certs/client.crt          # The path of the certificate content file. The {{br_ent.name}} tool reads the file from path /usr/local/certs/<subpath>.
              name: client-crt                                
              subPath: client.crt                             
            - mountPath: /usr/local/certs/client.key          # The path of the certificate private key file.
              name: client-key
              subPath: client.key
            - mountPath: /usr/local/certs/ca.crt              # The path of the CA root certificate file. 
              name: ca-crt
              subPath: ca.crt
      volumes:                                                # Create volumes to store the certificate files.
        - name: client-crt                                    # The name of the volume.
          secret:
            defaultMode: 420
            items:
              - key: tls.crt                                  # The name of the certificate content in the Secret.
                path: client.crt                              # The name of the certificate content file.
            secretName: client-cert                           # The name of the Secret that stores the certificate file.
        - name: client-key
          secret:
            defaultMode: 420
            items:
              - key: tls.key                                  # The name of the certificate private key in the Secret.
                path: client.key                              # The name of the certificate private key file.
            secretName: client-cert                           # The name of the Secret that stores the certificate file.
        - name: ca-crt                                        # The name of the volume to store the CA root certificate file.
          secret:
            defaultMode: 420
            items:
              - key: root.crt                                 # The name of the CA certificate content in the Secret.
                path: ca.crt                                  # The name of the CA certificate content file.
            secretName: ca-cert                               # The name of the Secret that stores the CA certificate file.
```

#### Configure environment variables to specify certificate file paths

In the YAML file for the backup job, add a volume to store the certificate files and configure environment variables to specify the paths to the certificate files. Then add the `--enable-ssl` and `--insecure-skip-verify` options to the command for backing up data.

!!! note

    Create Secrets to store the certificate files before creating the backup job, and make sure the Secrets are in the namespace where the backup job is located. For details, see [Enable mTLS in NebulaGraph](4.7.security/4.7.1.enable-mtls.md). 

The following YAML file creates a full backup job that configures environment variables to specify the paths to the certificate files:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: nebula-full-backup
spec:
  parallelism: 1
  ttlSecondsAfterFinished: 600
  template:
    spec:
      restartPolicy: OnFailure
      imagePullSecrets:
        - name: nebula-image
      containers:
        - image: reg.vesoft-inc.com/cloud-dev/br-ent:v3.7.0
          imagePullPolicy: Always
          name: backup
          env:
          - name: CA_CERT_PATH
            value: /credentials/ca.crt
          - name: CLIENT_CERT_PATH
            value: /credentials/client.crt
          - name: CLIENT_KEY_PATH
            value: /credentials/client.key
          command:
            - /bin/sh
            - -ecx
            - 'exec /usr/local/bin/br-ent backup full 
            --meta META_ADDRESS:9559 
            --storage s3://BUCKET_NAME
            --s3.access_key ACCESS_KEY 
            --s3.secret_key SECRET_KEY 
            --s3.region REGION 
            --s3.endpoint https://s3.REGION.amazonaws.com
            --enable-ssl
            --insecure-skip-verify'
          volumeMounts:
          - name: credentials
            mountPath: /credentials
        - name: auth-sidecar
          imagePullPolicy: Always
          image: reg.vesoft-inc.com/cloud-dev/nebula-certs:latest
          volumeMounts:
          - name: credentials
            mountPath: /credentials
      volumes:
      - name: credentials
        emptyDir:
          medium: Memory
```


## Restore

### Notes

- After the data recovery is successful, a new cluster will be created and the old cluster will not be deleted by default. You can decide whether to delete the old cluster yourself. The name of the new cluster is automatically generated by the Operator.

- There will be a period of service unavailability during the data recovery process, so it is recommended to operate during a low period of business activity.

<!-- ### Recovery Process

The recovery process is as follows:

1. Verify the NebulaRestore field, check if the specified NebulaGraph cluster exists, and verify if remote S3 storage access is normal.

2. Download the metadata information of the backup cluster according to the backupName, and parse it to obtain the physical topology of the backup cluster. Perform an isomorphism check with the topology of the cluster to be restored.

3. Copy the Spec configuration of the backup cluster and create a new cluster for restoring data. Confirm that there are sufficient resources for scheduling before starting the cluster.

4. The init container of the Metad Pod downloads the backup data. After the download is successful, start the Metad container. After all containers are running, the Operator calls the Metad interface to load the backup data.

5. The init container of the Storaged Pod downloads the backup data. After the download is successful, the agent container performs data playback. After the playback is successful, the Storaged container is started. After all containers are running, the Graphd container is started.

6. When the cluster is ready, the Operator calls the agent interface to clear the downloaded backup data and remove the init container configuration of the current cluster. -->

### Restore from an S3 protocol-compatible storage service

When restoring data from an S3 protocol-compatible storage service, you need to create a Secret to store the credentials for accessing the compatible S3 protocol service. Then create a resource object (NebulaRestore) for restoring the data, which instructs NebulaGraph Operator to create a new NebulaGraph cluster based on the information defined in this resource object and restore the backup data to the newly created cluster.

Here is an example YAML for restoring data based on the backup file `BACKUP_2023_02_12_10_04_16`:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: aws-s3-secret
type: Opaque
data:
  access-key: QVNJQVE0WFlxxx
  secret-key: ZFJ6OEdNcDdxenMwVGxxx
---
apiVersion: apps.nebula-graph.io/v1alpha1
kind: NebulaRestore
metadata:
  name: restore1
spec:
  br:
    clusterName: nebula
    backupName: "BACKUP_2023_02_12_10_04_16"
    concurrency: 5
    s3:
      region: "us-west-2"
      bucket: "nebula-br-test"
      endpoint: "https://s3.us-west-2.amazonaws.com"
      secretName: "aws-s3-secret"
```

#### Parameter Description

- Secret

  |Parameter|Default Value|Description|
  |:---|:---|:---|
  |`metadata.name`|-|The name of the Secret.|
  |`type`|`Opaque`|The type of the Secret. See [Types of Secret](https://kubernetes.io/docs/concepts/configuration/secret/#secret-types) for more information.|
  |`data.access-key`|-|The AccessKey for accessing the S3 protocol-compatible storage service.|
  |`data.secret-key`|-|The SecretKey for accessing the S3 protocol-compatible storage service.|

- NebulaRestore
  
  |Parameter|Default Value|Description|
  |:---|:---|:---|
  |`metadata.name`|-|The name of the resource object NebulaRestore.|
  |`spec.br.clusterName`|-|The name of the original cluster that was backed up. Data is restored based on the original cluster and a new cluster is created with a name automatically generated.|
  |`spec.br.backupName`|-|The name of the backup file. Data is restored based on this backup file.|
  |`spec.br.concurrency`|`5`|The number of concurrent downloads when restoring data. The default value is `5`.|
  |`spec.br.s3.region`|-| The geographical region where the S3 storage bucket is located.|
  |`spec.br.s3.bucket`|-|The name of the S3 storage bucket where backup data is stored.|
  |`spec.br.s3.endpoint`|-|The access address of the S3 storage bucket.|
  |`spec.br.s3.secretName`|-|The name of the Secret that is used to access the S3 storage bucket.|


### Restore from Google Cloud Storage

When restoring data from Google Cloud Storage, you need to create a Secret to store the credentials for accessing Google Cloud Storage. Then create a resource object (NebulaRestore) for restoring the data, which instructs NebulaGraph Operator to create a new NebulaGraph cluster based on the information defined in this resource object and restore the backup data to the newly created cluster.

Here is an example YAML for restoring data based on the backup file `BACKUP_2023_02_12_10_04_16`:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: gs-secret
type: Opaque
data:
  credentials: <GOOGLE_APPLICATION_CREDENTIALS_JSON>
---
apiVersion: apps.nebula-graph.io/v1alpha1
kind: NebulaRestore
metadata:
  name: restore1
spec:
  config:
    clusterName: nebula
    backupName: "BACKUP_2024_01_12_10_04_16"
    concurrency: 3
    gs:
      location: us-central1
      bucket: "nebula-br-test"
      secretName: "gs-secret"
```

#### Parameter Description

- Secret

  |Parameter|Default Value|Description|
  |:---|:---|:---|
  |`metadata.name`|-|The name of the Secret.|
  |`type`|`Opaque`|The type of the Secret. See [Types of Secret](https://kubernetes.io/docs/concepts/configuration/secret/#secret-types) for more information.|
  |`data.credentials`|-|The JSON string that represents your service account key provided by Google Cloud.|

- NebulaRestore

  ｜Parameter｜Default Value｜Description｜
  ｜:---｜:---｜:---｜
  ｜`metadata.name`｜-｜The name of the resource object NebulaRestore.｜
  ｜`spec.config.clusterName`｜-｜The name of the original cluster that was backed up. Data is restored based on the original cluster and a new cluster is created with a name automatically generated. ｜
  ｜`spec.config.backupName`｜-｜The name of the backup file. Data is restored based on this backup file. ｜
  ｜`spec.config.concurrency`｜`5`｜The number of concurrent downloads when restoring data. The default value is `5`. ｜
  ｜`spec.config.gs.location`｜-｜The geographical region where the GCS bucket is located. ｜
  ｜`spec.config.gs.bucket`｜-｜The name of the GCS bucket where backup data is stored. ｜
  ｜`spec.config.gs.secretName`｜-｜The name of the Secret that is used to access the GCS bucket. ｜



After setting up the YAML file for restoring the data, run the following command to start the restore job:

```bash
kubectl apply -f <restore_file_name>.yaml
```

Run the following command to check the status of the NebulaRestore object.

```bash
kubectl get rt <NebulaRestore_name> -n <namespace>

# Output example:
NAME       STATUS     STARTED   COMPLETED   AGE
restore1   Complete   67m       59m         67m
```

After the restore job is completed, a new NebulaGraph cluster is created with the name automatically generated by the Operator. To check the status of the new cluster:

```bash
kubectl get nc -n <namespace>

# Output example:

NAME     GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE
nebula   1                1              1               1             3                  3                2d3h
ngxvsm   1                1              1               1             3                  3                92m  # The newly created cluster.
```