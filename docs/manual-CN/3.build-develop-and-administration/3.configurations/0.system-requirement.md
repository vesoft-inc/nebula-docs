# 运行配置要求

## 生产环境

### 生产环境部署方式

* 3 个元数据服务进程 `metad`
* 至少 3 个存储服务进程 `storaged`
* 至少 3 个查询引擎服务进程 `graphd`

以上进程都无需独占机器。例如一个由 5 台机器组成的集群：A、B、C、D、E，可以如下部署：

* A：metad, storaged, graphd
* B：metad, storaged, graphd
* C：metad, storaged, graphd
* D：storaged, graphd
* E：storaged, graphd

> 同一个集群不要跨机房部署。
> metad 每个进程都会创建一份元数据存储副本，因此通常只需 3 个进程，storage 进程数量不影响图空间数据的副本数量。

### 服务器配置要求(标准配置)

以 AWS EC2 c5d.12xlarge 为例：

* 处理器：48 core
* 内存：96 GB
* 存储：2 * 900 GB, NVMe SSD
* Linux 内核：3.9 或更高版本，通过命令 `uname -r` 查看
* glibc：2.12 或更高版本，通过命令 `ldd --version` 查看

## 测试环境

* 1 个元数据服务进程 `metad`
* 至少 1 个存储服务进程 `storaged`
* 至少 1 个查询引擎服务进程 `graphd`

例如一个有 3 台机器的集群：A、B、C 可以如下部署：

* A：metad、storaged、graphd
* B：storaged、graphd
* C：storaged、graphd

### 服务器配置要求(最低配置)

以 AWS EC2 c5d.xlarge 为例：

* 处理器：4 core
* 内存：8 GB
* 存储：100 GB, SSD

## 资源估算

* 存储空间（全集群）：边数量 平均边属性的字节数 * 2.5
* 内存（全集群）：边数量 * 4 字节 + RocksDB 实例数量 * (write_buffer_size * max_write_buffer_number + rocksdb_block_cache), 其中 `etc/nebula-storaged.conf` 文件中 `--data_path` 项中的每个目录对应一个 RocksDB 实例
* 图空间 partition 数量：全集群硬盘数量 * （2 至 10 —— 硬盘越好该值越大）

## 关于机械硬盘和千兆网络

**Nebula Graph** 设计时主要针对的硬件设备是 NVMe SSD 和万兆网。没有专门对于机械磁盘和千兆网络做过适配，以下是一些需调整的参数：

* etc/nebula-storage.conf：
  * --raft_rpc_timeout_ms= 5000 至 10000
  * --rocksdb_batch_size= 4096 至 16384
  * --heartbeat_interval_secs = 30 至 60
  * --raft_heartbeat_interval_secs = 30 至 60
* Spark Writer:

```text
rate: {
      timeout: 5000 至 10000
    }
```

* go-importer:
  * batchSize: 10 至 50
  * concurrency: 1 至 10
  * channelBufferSize：100 至 500
* partition 值为全集群硬盘数量 2 倍
