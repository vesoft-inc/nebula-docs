# Operating Configuration Requirements

## Production Environment

### Production Environment Deployment Method

* 3 metadata service process metad
* At least 3 storage service processes storaged
* At least 3 query engine service processes graphd

None of the above processes need to a single machine. For example, a cluster of 5 machines: A, B, C, D, E can be deployed as follows:

* A: metad, storaged, graphd
* B: metad, storaged, graphd
* C: metad, storaged, graphd
* D: storaged, graphd
* E: storaged, graphd

> Do not deploy the same cluster across places.
> Each metad process creates a copy of the metadata storage, so usually only 3 processes are needed, and the number of storage processes does not affect the number of copies of graph space data.

### Server Configuration Requirements (Standard)

Take AWS EC2 c5d.12xlarge as an example:

* CPU: 48 core
* Memory: 96 GB
* Storage: 2 * 900 GB, NVMe SSD
* Linux kernel: 3.9 or higher, check with the command `uname -r`
* glibc: 2.12 or higher, check with the command `ldd --version`

## Test Environment

* 1 metadata service process metad
* At least 1 storage service process storaged
* At least 1 query engine service process graphd

For example, a cluster with 3 machines: A, B, C can be deployed as follows:

* A: metad, storaged, graphd
* B: storaged, graphd
* C: storaged, graphd

### Server Configuration Requirements (Minimum)

Take AWS EC2 c5d.xlarge as an example:

* CPU: 4 core
* Memory: 8 GB
* Storage: 100 GB, SSD

## Resource Estimation

* Storage space (full cluster): number of edges Average number of bytes of edge attributes * 2.5
* Memory (full cluster): number of edges * 4 bytes + number of RocksDB instances * (write_buffer_size * max_write_buffer_number + rocksdb_block_cache), where each directory in the `--data_path` item in the `etc/nebula-storaged.conf` file corresponds to a RocksDB instance
* Number of partitions in the graph space: number of hard disks in the full cluster * (2 to 10, the better the hard disk, the greater the value)

## About Mechanical Hard Disks and Gigabit Networks

**Nebula Graph** is designed for are NVMe SSD hardware and 10 Gigabit Network. There is no special adaptation for mechanical disks and gigabit networks. The following are some parameters to be adjusted:

* etc/nebula-storage.conf:
  * --raft_rpc_timeout_ms= 5000 to 10000
  * --rocksdb_batch_size= 4096 to 16384
  * --heartbeat_interval_secs = 30 to 60
  * --raft_heartbeat_interval_secs = 30 to 60
* Spark Writer:

```text
rate: {
      timeout: 5000 to 10000
    }
```

* go-importer:
  * batchSize: 10 to 50
  * concurrency: 1 to 10
  * channelBufferSize: 100 to 500
* The partition value is twice the number of hard disks in the full cluster
